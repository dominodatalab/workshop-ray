{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0abf0f9b-94fc-4c59-803b-a014cec8b27b",
   "metadata": {},
   "source": [
    "# Beginner Ray: Embarrassingly Parallel Workloads using Ray Core\n",
    "\n",
    "[Ray](https://docs.ray.io/en/latest/index.html) has a rich ecosystem of libraries and frameworks for Machine Learning.\n",
    "These are built on top of the simple primitives provided by [Ray Core](https://docs.ray.io/en/latest/ray-core/walkthrough.html).\n",
    "This notebook will walk through a complete example using **remote tasks** in Ray Core, to cover the following concepts:\n",
    "* Setting up your Ray Cluster in Domino\n",
    "* Connecting to your Ray Cluster in Domino\n",
    "* Submitting remote Tasks using the ray.remote decorator and retrieving results\n",
    "* Interpreting logs and errors for basic troubleshooting\n",
    "* Effectively distributing tasks in parallel while avoiding common [anti-patterns](https://docs.ray.io/en/latest/ray-core/tasks/patterns/index.html)\n",
    "* Bonus: Ray Cluster auto-scaling in Domino\n",
    "\n",
    "This tutorial is designed to serve two purposes:\n",
    "1. Provide a conceptual introduction to Ray, which will serve as a foundation for the Intermediate tutorials and further explorations with Ray.\n",
    "2. Function as a practical example for writing custom distributed code using only Ray Core, which can be applied directly to certain types of repeated simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201196b1-f364-4fe2-9264-cb4ace826187",
   "metadata": {},
   "source": [
    "## Sample problem: Monte Carlo Approximation of Pi\n",
    "\n",
    "First, let's introduce our simple example problem: approximating the value of Pi using a Monte Carlo approach. Wikipedia has a good explanation and visualization [here](https://en.wikipedia.org/wiki/Monte_Carlo_method#Overview). The procedure is as follows:\n",
    "* Generate a series of random points in a 1x1 square (x and y between 0 and 1).\n",
    "* Calculate for each point whether it falls inside a radius of 1.\n",
    "* Multiply the ratio of the number of points falling **inside** the unit radius and the **total** number of points to approximiate Pi.\n",
    "\n",
    "Below is a code snippet to do this, with no dependencies outside a random number generator and the time library to benchmark the computation time. Try experimenting with the sample size and see how it impacts the accuracy of the approximation and the time required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3201aedc-f5cb-4240-8741-18981c3ff2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def monte_carlo_pi_sampler(n_samples, debug=False):\n",
    "    n_inside_quadrant = 0\n",
    "    if debug:\n",
    "        print(f\"monte_carlo_pi_sampler getting ready to do {n_samples} samples\")\n",
    "    for _ in range(n_samples):\n",
    "        x = random.uniform(0,1)\n",
    "        y = random.uniform(0,1)\n",
    "        r = (x**2 + y**2)**0.5\n",
    "        if r <= 1:\n",
    "            n_inside_quadrant += 1\n",
    "    if debug:\n",
    "        print(f\"monte_carlo_pi_sampler found {n_inside_quadrant} inside a unit circle\")\n",
    "    return n_inside_quadrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9517e06c-d85a-4473-bef6-47df9e3a6eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Try experimenting with different sample sizes, and turning on debug mode\n",
    "n_total = 10**6\n",
    "n_inside = monte_carlo_pi_sampler(n_total)\n",
    "pi = 4*n_inside/n_total\n",
    "\n",
    "time_elapsed = time.time() - start\n",
    "print(f'Pi is approximately {pi}.')\n",
    "print(f'It took {time_elapsed:.2f}s with {n_total} total samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c9a014-8f1a-407e-97af-8b865bf59b62",
   "metadata": {},
   "source": [
    "## Setting up and connecting to your Ray cluster\n",
    "\n",
    "You should already have setup a workspace as recommended in the `README.md`, which includes the required setup for the Ray cluster.\n",
    "Remember that the following properties are set as part of the Workspace Settings in Domino:\n",
    "* Whether there is a Ray cluster attached at all\n",
    "* How many workers the cluster starts with, and whether it can auto-scale by adding more workers\n",
    "* What hardware tier the cluster uses for head and worker nodes\n",
    "* What software environment the cluster uses\n",
    "* Whether additional local storage is attached (not relevant in this tutorial)\n",
    "\n",
    "See the README for more details about the recommended settings.\n",
    "\n",
    "Inside the workspace, you should have a tab for the **Ray Web UI**.\n",
    "Duplicate your workspace tab so you can see the Ray Web UI side-by-side with this notebook as you run the rest of the tutorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c55430-3285-44a2-b4ea-00908586de1b",
   "metadata": {},
   "source": [
    "### Connecting to a \"local\" Ray cluster (the wrong way)\n",
    "\n",
    "Below is some typical code for initializing a Ray cluster.\n",
    "Beware of the fact that this will NOT connect you to your Domino on-demand cluster!\n",
    "Instead, it will create a new Ray cluster that lives only on the \"local\" workspace node.\n",
    "It is easy to be fooled into thinking that you are correctly connected to your Ray cluster after doing this, especially if using a large Hardware Tier, because Ray can still effectively **parallelize** work on a single multi-core machine.\n",
    "However, if you were to run the remainder of this notebook after initializing Ray like this, you could see in the Ray Web UI that nothing is happening - your work would not be **distributed** to the multiple nodes of the Domino cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ad6b02-cf68-492b-bb05-58a4f508d1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Don't initialize Ray this way on Domino!\n",
    "\n",
    "import ray\n",
    "if ray.is_initialized() == False:\n",
    "    ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077f9cb8-618f-433b-a035-9047a4b9756d",
   "metadata": {},
   "source": [
    "One way to prove that Ray is not correctly connected to your Domino cluster is by inspecting the list of nodes.\n",
    "The first thing you may notice is that there is only one node listed, whereas we expect 3 nodes (1 head node and 2 worker nodes).\n",
    "If you look closer at the IP address of the node, you can also see that it does not match any of the IP addresses in the Ray Web UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f07dab0-b0f2-44e2-a9f2-f9b822e292ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5116e7-2ba6-43ac-a062-528efe2305f6",
   "metadata": {},
   "source": [
    "### Disconnecting from and shutting down your Ray cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd160164-889c-436d-88a3-37906be293d3",
   "metadata": {},
   "source": [
    "Notice the `if ray.is_initialized()` statement above, which will prevent errors about Ray already being running if you try to initialize it again.\n",
    "This also means that we need to shut down our connection to this cluster before we can reconnect the \"correct\" way below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119127e0-b85f-4bb2-a61a-67e1632c87e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc02d4c5-64d5-479d-bb16-3df4ee40084d",
   "metadata": {},
   "source": [
    "This can also be used to reset the connection to the Domino Ray cluster.\n",
    "Note that in that case it only shuts down the **processes** running on the Ray nodes, not the head or worker nodes themselves; to completely restart the cluster, stop and start the Workspace.\n",
    "\n",
    "There are a few cases where you might run Ray as a \"local cluster\" like this deliberately even in Domino.\n",
    "* To test some code locally as a baseline when troubleshooting issues with your Ray cluster, especially suspected mismatches between workspace and cluster environments.\n",
    "* To use Ray on a single large machine on earlier versions of Domino that don't support On-Demand Ray clusters, or any other scenario when you are unable to launch a workspace with a Ray cluster attached."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514bf62c-7971-4f59-940f-fd0751f7f7a2",
   "metadata": {},
   "source": [
    "### Connecting to your Ray cluster (the right way)\n",
    "\n",
    "Domino provides the information needed to connect to your Ray cluster via environment variables.\n",
    "After initializing Ray this way, you should see subsequent operations in Ray represented in the Ray Web UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9a7c7e-6613-4bde-a0b4-20e636c1f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import os\n",
    "\n",
    "if ray.is_initialized() == False:\n",
    "    service_host = os.environ[\"RAY_HEAD_SERVICE_HOST\"]\n",
    "    service_port = os.environ[\"RAY_HEAD_SERVICE_PORT\"]\n",
    "    ray.init(f\"ray://{service_host}:{service_port}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eb15ba-310b-4a14-8aec-a148cbc80492",
   "metadata": {},
   "source": [
    "Inspecting the nodes again, you should also see that the IP addresses listed now match what you see in the Ray Web UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76b1cfe-38ba-46c3-bda1-1fec6cfda5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33547cc8-3fa4-433b-8c80-f3c2ec18a501",
   "metadata": {},
   "source": [
    "## Submitting work to the Ray cluster\n",
    "\n",
    "### Tasks (with ray.remote), futures, and results\n",
    "\n",
    "Now that we have initialized Ray, we can submit work to the cluster by defining a function using the `ray.remote` decorator.\n",
    "Wrapping our Pi example this way is extremely simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7596d-6e18-4d0c-9a16-4d47f6f2b0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def ray_monte_carlo_pi_sampler(n_samples, debug=False):\n",
    "    return monte_carlo_pi_sampler(n_samples, debug=debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10924fe5-c259-4b94-b436-e3f21f6c9911",
   "metadata": {},
   "source": [
    "To submit this to the cluster as a Task, call the function using `.remote`. Some important things to remember:\n",
    "* When you call a remote function, it returns a `future` instead of the actual result.\n",
    "* Ray will start executing the function immediately - Ray tasks do NOT use \"lazy execution\".\n",
    "* To get the actual result, call `.get` on the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08200e86-a7f1-4e05-a85a-baa5f9ece4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = 10**6\n",
    "n_inside_future = ray_monte_carlo_pi_sampler.remote(n_total)\n",
    "print('So far, we have only submitted our function call and gotten a future back:')\n",
    "n_inside_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1c8294-5184-472f-a673-1ec72cfcd76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inside = ray.get(n_inside_future)\n",
    "print(f'Now we have the final result:')\n",
    "n_inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc78ddf5-0643-40a6-839f-2831be6bf589",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = 4*n_inside/n_total\n",
    "print(f'Pi is approximately {pi}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf37a32-3f5f-4648-8050-666ef3d45d81",
   "metadata": {},
   "source": [
    "Note that `.get` will be a **blocking** call, meaning it will wait for the task to finish. On the other hand, `.remote` is **non-blocking** because it immediately returns a future. Let's run the above sequence in a single cell with timing to demonstrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c808c871-7767-4b22-9588-f5f2f64a6943",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "n_total = 10**7\n",
    "n_inside_future = ray_monte_carlo_pi_sampler.remote(n_total)\n",
    "\n",
    "print(f'Submitting took {time.time()-start:.2f}s')\n",
    "\n",
    "n_inside = ray.get(n_inside_future)\n",
    "print(f'The full calculation took {time.time()-start:.2f}s with {n_total} total samples')\n",
    "\n",
    "pi = 4*n_inside/n_total\n",
    "print(f'Pi is approximately {pi}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4127b06-1fae-4793-be8d-19c6f899a2f7",
   "metadata": {},
   "source": [
    "If you are watching the Ray Web UI in parallel to running this notebook, you should see evidence that this function is running on the cluster!\n",
    "However, all we've done so far is move the work from our local machine to the head node.\n",
    "Nothing is running in parallel, and all the work is being done on a single cluster node.\n",
    "We'll fix that in the next section, but first we'll take a very important detour into basic troubleshooting tips."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20883234-4db2-41c3-a8f9-e9442e95e664",
   "metadata": {},
   "source": [
    "### Logs, errors, and PIDs\n",
    "\n",
    "You may have noticed the `debug` option we have been ignoring in the `monte_carlo_pi_sampler` function. Now that you have the basics of futures and blocking vs non-blocking calls, let's use that option to generate some print statements from inside the Ray tasks. Here is what the debug output looks like without Ray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69146e1f-a733-4354-a0d8-2aa3422e7b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "monte_carlo_pi_sampler(10**6, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b581380-168c-49ea-8888-e9066bfbc809",
   "metadata": {},
   "source": [
    "Now let's run the Ray version in debug mode. Try running the following two cells two ways:\n",
    "* First, wait a few seconds between them\n",
    "* Second, run them back-to-back\n",
    "\n",
    "Notice the **PID** of the Ray processes the print statements come from, and compare them to what you see in the Ray Web UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e66e66-88d0-4f01-9096-2acc2ccba2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = 10**6\n",
    "n_inside_future = ray_monte_carlo_pi_sampler.remote(n_total, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc257bf-b292-436d-8437-0e51a316a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inside = ray.get(n_inside_future)\n",
    "pi = 4*n_inside/n_total\n",
    "print(f'Pi is approximately {pi}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a305f33-daaa-4218-bbae-541469bce055",
   "metadata": {},
   "source": [
    "Notice how it will print out to your current cell's output whenever Ray gets to that point in the calculation, regardless of what cells you have run in the meantime.\n",
    "In other words, the print statements from Ray tasks can come in a **different order** compared to print statements in the local notebook depending on how you run the cells!\n",
    "In addition, there is just enough \"lag\" for printing from remote tasks that you may find the final Pi result displaying before the final `ray_monte_carlo_pi_sampler` printout, even though the final Pi result must clearly come only after all remote tasks are complete.\n",
    "\n",
    "Now let's trigger an obvious error and see what happens. First, try it without Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495c3967-7eaf-417e-aa02-11505c6afb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "monte_carlo_pi_sampler('a million', debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ef04bd-5775-45a1-9e46-e7e72fd74a50",
   "metadata": {},
   "source": [
    "Next, submit a Ray task with the same bad input and see what happens. You'll notice our first debug line print out, but nothing after that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f756bf-4e91-4a49-bdfd-ca0ad268c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inside_future = ray_monte_carlo_pi_sampler.remote('a million', debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22963abf-7a08-4f14-9649-b6020818e3b8",
   "metadata": {},
   "source": [
    "Finally, try to get the result. Now we see the error message! Unlike the print statements, the error trace does not appear \"as soon as it happens\" - we have to try to get the result first. Notice how the stack trace includes the full \"path\" of the task through the Ray code, and the meaningful part of the error is really the last few lines.\n",
    "\n",
    "Don't spend too much time staring at the details here - just keep in mind this section of the tutorial as a reference in case you are ever debugging remote functions in a \"real\" scenario. Comparing the structure of this \"known\" error to errors you encounter in the wild may help with interpreting and troubleshooting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bb8640-f565-4ddd-978e-5c4ac5219d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inside = ray.get(n_inside_future)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dc4f22-aa98-4c17-af3a-59c08474c9ca",
   "metadata": {},
   "source": [
    "## Parallelize and distribute the work\n",
    "\n",
    "The Monte Carlo approximation of Pi is a good example of an **Embarassingly parallel** problem, because it is very easy to break it up into independent chunks for parallel processing. However, there are some nuances and pitfalls to this process.\n",
    "\n",
    "### The importance of batching\n",
    "\n",
    "At one extreme, we have the code in our previous section - technically we are using Ray, but we are getting no benefits because we have not actually broken up the computation. Nothing is parallelized at all. At the other extreme, we could consider sending each random point generation (and radius calculation) as a separate task to the cluster. This would incur unnecessary overhead, as explained in the [Ray docs](https://docs.ray.io/en/latest/ray-core/tasks/patterns/fine-grained-tasks.html).\n",
    "\n",
    "Instead, we should use our existing code to calculate **batches** of points. At this point, you may notice a clever thing in the original code: `monte_carlo_pi_sampler` simply returns a count of how many points fall inside the unit radius, and the actual calculation of Pi happens outside the function. This is deliberate, to make it easier to split the calculation up into batches like below. If you are adapting some existing code to make use of Ray, you will often need to do some restructuring to get a similar structure.\n",
    "\n",
    "First, let's just write and test a new \"batching\" function with no parallel or distributed processing as a baseline. We'll include all the timing and print statements inside this function for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9217a6b1-c7b3-4126-8930-fd9056fe4405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_pi(sample_batch_sizes, debug=False):\n",
    "    start = time.time()\n",
    "    total_samples = sum(sample_batch_sizes)\n",
    "    total_inside = 0\n",
    "    for i,n in enumerate(sample_batch_sizes):\n",
    "        total_inside += monte_carlo_pi_sampler(n, debug=debug)\n",
    "        print(f\"Time check after batch {i+1}: {time.time()-start:.2f}s\")\n",
    "    pi = 4*total_inside/total_samples\n",
    "    print(f'Pi is approximately {pi}.')\n",
    "    print(f'It took {time.time()-start:.2f}s with batches: {sample_batch_sizes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da1405b-c774-4825-9a0b-4cd5f03a6fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "approximate_pi(3*[10**7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f7fe5-1814-4727-9e4f-478ccc349745",
   "metadata": {},
   "source": [
    "### First try at distributing (the wrong way)\n",
    "Now modify our batching function and try to distribute each batch to cluster workers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc964dd0-7167-4b4b-93e4-e558944c94ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ray_approximate_pi_wrong(sample_batch_sizes, debug=False):\n",
    "    start = time.time()\n",
    "    total_samples = sum(sample_batch_sizes)\n",
    "    total_inside = 0\n",
    "    for i,n in enumerate(sample_batch_sizes):\n",
    "        n_inside_future = ray_monte_carlo_pi_sampler.remote(n, debug=debug)\n",
    "        total_inside += ray.get(n_inside_future)\n",
    "        print(f\"Time check after batch {i+1}: {time.time()-start:.2f}s\")\n",
    "    pi = 4*total_inside/total_samples\n",
    "    print(f'Pi is approximately {pi}.')\n",
    "    print(f'It took {time.time()-start:.2f}s with batches: {sample_batch_sizes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1228955a-dc62-4b33-ad02-9ea38439d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_approximate_pi_wrong(3*[10**7], debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0222cb35-23e7-4d99-ac2b-b16c760c2775",
   "metadata": {},
   "source": [
    "Can you figure out what we are doing wrong? Why isn't it running in parallel? It is still only using the head node! (The answer is a common [antipattern](https://docs.ray.io/en/latest/ray-core/tasks/patterns/ray-get-loop.html)/pitfall for beginners.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb76aedc-a205-494c-bfde-5b463a50f93d",
   "metadata": {},
   "source": [
    "### Second try at distributing (the right way)\n",
    "\n",
    "To actually parallelize the work, it's important to submit all our batches first before attempting to get any results. The below function does this the \"correct\" way, and is the first time in this notebook we submit any tasks to the Ray **worker** nodes (as opposed to just the **head** node) - hooray!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e45f7e2-dac0-4f93-a3df-90c0c608bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ray_approximate_pi(sample_batch_sizes, debug=False):\n",
    "    start = time.time()\n",
    "    total_samples = sum(sample_batch_sizes)\n",
    "    n_inside_futures = []\n",
    "    for i,n in enumerate(sample_batch_sizes):\n",
    "        n_inside_futures.append(ray_monte_carlo_pi_sampler.remote(n, debug=debug))\n",
    "        print(f'Time check after batch {i+1} submit: {time.time()-start:.2f}s')\n",
    "    total_inside = 0\n",
    "    for j, future in enumerate(n_inside_futures):\n",
    "        total_inside += ray.get(future)\n",
    "        print(f'Time check after batch {j+1} result: {time.time()-start:.2f}s')\n",
    "    pi = 4*total_inside/total_samples\n",
    "    print(f'Pi is approximately {pi}.')\n",
    "    print(f'It took {time.time()-start:.2f}s with batches: {sample_batch_sizes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85eb987-7eb7-4198-8a29-abf1d2883798",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_approximate_pi(3*[10**7], debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7409d42-1e07-4fd4-bb1b-cb61f2602ed7",
   "metadata": {},
   "source": [
    "Since this is the first time we are submitting Tasks to the worker nodes, this is the first time you will see any worker processes with **PIDs** (with each worker identified by **ip address**) in the Ray Web UI. These processes will take a second or so to startup, so you may notice a second or two difference in the timing of the previous cell the first time you run it. This is to be expected! Once the worker processes are started, they will remain until/unless you shutdown your Ray connection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829ee417-2597-4960-96fe-268110d00604",
   "metadata": {},
   "source": [
    "### Alternate ways to collect results\n",
    "Ray can handle a list of futures just fine, so we can make our code a little more concise with no problems.\n",
    "For very small batches, you may also notice an improvement in performance getting results this way, compared to the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc2cc2-e410-407f-8afe-f35c7fb84daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ray_approximate_pi_alt(sample_batch_sizes, debug=False):\n",
    "    start = time.time()\n",
    "    total_samples = sum(sample_batch_sizes)\n",
    "    n_inside_futures = []\n",
    "    for i,n in enumerate(sample_batch_sizes):\n",
    "        n_inside_futures.append(ray_monte_carlo_pi_sampler.remote(n, debug=debug))\n",
    "        print(f\"Time check after batch {i+1} submit: {time.time()-start:.2f}s\")\n",
    "    total_inside = sum(ray.get(n_inside_futures))\n",
    "    pi = 4*total_inside/total_samples\n",
    "    print(f'Pi is approximately {pi}.')\n",
    "    print(f'It took {time.time()-start:.2f}s with batches: {sample_batch_sizes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99102789-9f59-4e74-8d75-5b7b57df6276",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_approximate_pi_alt(3*[10**7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea50cc8-669d-47bc-a4f0-24cd292aff02",
   "metadata": {},
   "source": [
    "In fact, the previous section example of calling `ray.get` one by one in order is actually [another antipattern](https://docs.ray.io/en/latest/ray-core/tasks/patterns/submission-order.html). In our case, it doesn't really matter because we have to wait for all tasks to be finished before doing the remaining computations anyway. (And besides, if you use the default batches provided, they are all the same size and so are expected to take the same amount of time to compute.) However, real problems will not always be so tidy, and using `ray.wait` as suggested by the above link will return tasks as they finish no matter the order of submission. Check out the Intermediate tutorial for an example using `ray.wait`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902cc330-83c6-4d09-b455-e6dd78a923bb",
   "metadata": {},
   "source": [
    "## Putting it all together, with bonus autoscaling demo\n",
    "\n",
    "Now that we've walked through the important concepts for getting started on Ray, let's put all the code together in one place, and do a bit of a \"stress test\".\n",
    "\n",
    "Domino On-Demand clusters have the (optional) ability to **autoscale**, meaning they can add workers when needed.\n",
    "Restart your workspace as follows to enable autoscaling:\n",
    "* Find the Workspace **Settings** in the left navigation pane.\n",
    "* Click **Edit Settings**.\n",
    "* Go to Step 3 for **Compute Cluster** settings.\n",
    "* Check the box to **Auto-scale workers**, and enter **4** for the max. (Min should be at 2.)\n",
    "* Click **Save and Restart**.\n",
    "\n",
    "By default, all On-Demand clusters (including Ray) will scale up when the average CPU utilization is 80%, and will scale back down when it is below the threshold for 5 minutes.\n",
    "This is [configurable](https://docs.dominodatalab.com/en/latest/admin_guide/71d6ad/central-configuration/#compute-cluster-auto-scaling) by the Domino Admin, who can also choose to disable autoscaling for any cluster type.\n",
    "\n",
    "Once the workspace has restarted, you can start at this section of the notebook - no need to rerun previous cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4757ebff-99a2-4c70-be72-76564a87cc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import ray\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457a28c8-2c3d-48d8-bbb1-5cd3c84a0e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to connect to the Domino Ray cluster correctly!\n",
    "\n",
    "if ray.is_initialized() == False:\n",
    "    service_host = os.environ[\"RAY_HEAD_SERVICE_HOST\"]\n",
    "    service_port = os.environ[\"RAY_HEAD_SERVICE_PORT\"]\n",
    "    ray.init(f\"ray://{service_host}:{service_port}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5ab555-dcdc-43d8-8b0e-c48c18b11b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the main workhorse function for our problem, written \"before Ray\".\n",
    "\n",
    "def monte_carlo_pi_sampler(n_samples, debug=False):\n",
    "    n_inside_quadrant = 0\n",
    "    if debug:\n",
    "        print(f\"monte_carlo_pi_sampler getting ready to do {n_samples} samples\")\n",
    "    for _ in range(n_samples):\n",
    "        x = random.uniform(0,1)\n",
    "        y = random.uniform(0,1)\n",
    "        r = (x**2 + y**2)**0.5\n",
    "        if r <= 1:\n",
    "            n_inside_quadrant += 1\n",
    "    if debug:\n",
    "        print(f\"monte_carlo_pi_sampler found {n_inside_quadrant} inside a unit circle\")\n",
    "    return n_inside_quadrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cfdf6a-e84a-411e-a1ef-2e09136f0dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we wrap it with the ray.remote decorator!\n",
    "\n",
    "@ray.remote\n",
    "def monte_carlo_pi_sampler_on_ray(n_samples, debug=False):\n",
    "    return monte_carlo_pi_sampler(n_samples, debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040b1b47-e32f-4746-9bd4-12ab15c9be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we write the code to submit tasks to the Ray cluster\n",
    "\n",
    "def approximate_pi_on_ray(sample_batch_sizes, debug=False):\n",
    "    start = time.time()\n",
    "    total_samples = sum(sample_batch_sizes)\n",
    "    n_inside_futures = []\n",
    "    for i,n in enumerate(sample_batch_sizes):\n",
    "        n_inside_futures.append(monte_carlo_pi_sampler_on_ray.remote(n, debug=debug))\n",
    "        print(f\"Time check after batch {i+1} submit: {time.time()-start:.2f}s\")\n",
    "    total_inside = sum(ray.get(n_inside_futures))\n",
    "    pi = 4*total_inside/total_samples\n",
    "    print(f'Pi is approximately {pi}.')\n",
    "    print(f'It took {time.time()-start:.2f}s with batches: {sample_batch_sizes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dc93b7-a563-4f37-9e8d-bc8ce4b51cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kick off some small batches to make sure everything is working\n",
    "approximate_pi_on_ray(3*[10**6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315f33a6-ea04-438e-91bf-928073a3005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, try more and larger batches here to trigger the cluster to autoscale!\n",
    "approximate_pi_on_ray(10*[10**8], debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6a9a2c-089e-45b6-95cc-48e2b84eb092",
   "metadata": {},
   "source": [
    "### Congratulations!\n",
    "\n",
    "You have finished this Beginner tutorial on Ray Core, where we covered the following:\n",
    "* Setting up your Ray Cluster in Domino\n",
    "* Connecting to your Ray Cluster in Domino\n",
    "* Submitting remote Tasks using the ray.remote decorator and retrieving results\n",
    "* Interpreting logs and errors for basic troubleshooting\n",
    "* Effectively distributing tasks in parallel while avoiding common [anti-patterns](https://docs.ray.io/en/latest/ray-core/tasks/patterns/index.html)\n",
    "* Bonus: Ray Cluster auto-scaling in Domino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524fc34d-59f9-468d-9dbc-302727efdb2a",
   "metadata": {},
   "source": [
    "### What's next?\n",
    "\n",
    "The example in this tutorial is essentially a **simulation**, and one that can easily be broken up into smaller pieces.\n",
    "In other words, it is **Embarrassingly Parallel**.\n",
    "It requires passing very little data to each Task, because as a simulation it generates most of the data within the Task itself.\n",
    "The results to pass back from the Task are likewise very small.\n",
    "In a more realistic simulation, you will almost certainly be generating that data with Numpy arrays or similar constructs to take advantage of vectorized operations, rather than looping through simluated points one-by-one, but as long as this is done within the Task it doesn't change the basic structure of the problem.\n",
    "\n",
    "If your use-case happens to match this pattern, you can now use Ray to distribute your computations!\n",
    "\n",
    "If not, check out the Intermediate tutorials for more about the following topics:\n",
    "* Handling **large data**, passing it efficiently around the cluster when needed and avoiding unnecessary data transfer\n",
    "* Using **more Ray Core functionality**, like Actors and ray.wait\n",
    "* Integrating with **additional libraries**, like XGBoost and Ray Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b8bf02-72be-42e2-bfa6-508588343a47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
