{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3be8fe54-255d-47cd-beeb-32ee4e7653f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Intermediate Ray (part 1): More Ray Core and Dealing with Large Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c73c88-b652-489f-8708-a8bf4a7e9d83",
   "metadata": {},
   "source": [
    "This tutorial builds on the material in `1-Beginner-Ray-Core.ipynb`, and it is highly recommended to read and/or work through that notebook first.\n",
    "In particular, this notebook continues to explore the sample problem introduced in the first notebook: approximating the value of Pi using a Monte Carlo approach.\n",
    "\n",
    "In this notebook, that sample problem will be expanded to illustrate the following concepts:\n",
    "* More options for remote Task management with ray.wait and ray.cancel\n",
    "* Creating and scheduling remote Actors\n",
    "* Using the Ray object store with ray.put\n",
    "* Loading and processing data with Ray Data\n",
    "* Loading and processing data with Modin\n",
    "* Common pitfalls for larger-than-memory data\n",
    "* Bonus - performance improvements with dedicated local storage\n",
    "\n",
    "This tutorial is designed to serve two purposes:\n",
    "1. Round out the conceptual introduction to fundamental Ray concepts from the beginner notebook.\n",
    "2. Provide practical examples of loading and manipulating large data in Ray, which is a prerequisite and common stumbling block for making use of a wide variety of other packages and algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b798b9-5492-4a07-b8de-52d52f342a33",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Beginner notebook recap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644dc410-a355-451a-90a3-96f1718cdcc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "This notebook assumes you have a Ray cluster set up in Domino following the `README.md`; see the Beginner notebook for a more detailed explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f2a4d9-8d82-4cf8-88f5-101f7d440041",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Connecting to and inspecting your Ray cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca0880b-0875-4bd9-8288-dc29baf7e321",
   "metadata": {},
   "source": [
    "Always remember to connect to your Ray cluster in Domino like below, using the provided environment variables for the host and port.\n",
    "Your Ray code may still run without this step, but it will not be running on the cluster correctly!\n",
    "\n",
    "As in the Beginner notebook, it's recommended to duplicate the workspace tab in your browser, so you can have one showing this notebook side-by-side with the **Ray Web UI** as you work through the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6242b920-9c93-4520-8ff4-9c8108275184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75325e23-f2ee-43f1-ae85-827fcc29908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ray.is_initialized() == False:\n",
    "    service_host = os.environ[\"RAY_HEAD_SERVICE_HOST\"]\n",
    "    service_port = os.environ[\"RAY_HEAD_SERVICE_PORT\"]\n",
    "    ray.init(f\"ray://{service_host}:{service_port}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bae26b9-ae92-4f2b-9906-035b0ef3f1fa",
   "metadata": {},
   "source": [
    "In the beginner notebook, we also inspected the cluster by looking at `ray.nodes()`. Two more useful functions for inspecting the cluster are:\n",
    "* `ray.cluster_resources()` shows the total resources for the cluster, as well as CPU for each node\n",
    "* `ray.available_resources()` is very similar, but shows the *idle/available* resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2143bc1d-98f3-443b-9370-468e96752883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CPU': 18.0,\n",
       " 'node:10.0.40.94': 1.0,\n",
       " 'object_store_memory': 26028377700.0,\n",
       " 'memory': 57840795651.0,\n",
       " 'node:10.0.36.194': 1.0,\n",
       " 'node:10.0.46.72': 1.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c403f038-a57a-4e64-b499-6b04f84d5a19",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setting up our Monte Carlo approximation of Pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad2cc8e-9a04-4d82-8f66-5956f833e85f",
   "metadata": {},
   "source": [
    "Below we set up a remote function for running the Monte Carlo sampling to calculate Pi.\n",
    "\n",
    "This is a consolidated version of the code in the Beginner notebook - note that we now return the estimate of Pi directly.\n",
    "Multiple batches can still be combined to get a better estimate, by averaging the value of Pi for each.\n",
    "Each batch must have equal numbers of points OR the average must weight each sample Pi accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "654297dd-b3f0-4b44-a8a4-463be88f472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def mc_pi_single_batch(n_samples):\n",
    "    n_inside = 0\n",
    "    for _ in range(n_samples):\n",
    "        x = random.uniform(0,1)\n",
    "        y = random.uniform(0,1)\n",
    "        if (x**2 + y**2) <= 1:\n",
    "            n_inside += 1\n",
    "    return 4 * n_inside / n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a1bb44-f4a1-4353-8c41-f917254a538c",
   "metadata": {},
   "source": [
    "Check that everything is set up correctly by running a small batch, and verify in the Ray Web UI that this runs on the cluster.\n",
    "We expect to see a single process briefly run on the head node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e7a4b84-148f-4516-90ca-5c4801a5c838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi is approximately 3.140888 (from 1000000 samples in 0.77s)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "n = 10**6\n",
    "pi = ray.get(mc_pi_single_batch.remote(n))\n",
    "print(f\"Pi is approximately {pi} (from {n} samples in {time.time()-start:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba39cb5-f72d-48de-9c6d-8fba808dc3ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## More options for remote Task management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42a7f3d-a92b-4f19-900d-ff1e4f66a6b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "Our existing approximation of Pi works well enough, but has a few shortcomings:\n",
    "* We must decide the number of batches and samples in advance\n",
    "* We have no estimate of how accurate the approximation is\n",
    "\n",
    "To fix this, we can rewrite the code to estimate the error on Pi.\n",
    "Then, it would be convenient if we can decide what threshold of error is acceptable, and keep submitting more batches until we get the accuracy we want.\n",
    "(In statistical terms, our estimate of the error on Pi is an example of the [standard error of the mean](https://en.wikipedia.org/wiki/Standard_error#Standard_error_of_the_sample_mean);\n",
    "all that really matters here is that the error goes down as the number of batches goes up.)\n",
    "This mimics the pattern of many machine learning problems.\n",
    "\n",
    "However, using `ray.get` to get the results from each batch is not very flexible;\n",
    "it will **block** until all tasks you are getting results for have finished.\n",
    "If we want to keep checking results and submitting more Tasks as others finish, we will want a better way to do it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d672c9-8649-41c2-a094-7ba634a88caa",
   "metadata": {},
   "source": [
    "### Getting results as Tasks finish with ray.wait"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2dc592-9b36-46a4-9e1e-f6c71ca5718d",
   "metadata": {},
   "source": [
    "To overcome the fact that `ray.get` will block until all the tasks passed into it are finished, we turn to `ray.wait`.\n",
    "It does the following:\n",
    "* Return two lists, finished tasks and unfinished tasks.\n",
    "* The number of finished tasks to wait for is controlled by `num_returns` and defaults to 1. (It still returns the finished task as a list of length 1.)\n",
    "* It blocks until the requested number of tasks are finished, but allows processing those results while waiting for the remaining tasks.\n",
    "* When no tasks remain, it returns an empty list for unfinished tasks.\n",
    "* It does not matter what order tasks were submitted, or what order they are passed to `ray.wait` - it returns the first task(s) that are ready.\n",
    "\n",
    "To get the results of the finished tasks, you will still use `ray.get`, but now you know that the results in question are ready.\n",
    "All of this can be best illustrated with tasks that take very different amounts of time to complete, as below.\n",
    "(Check out the [python docs for list comprehensions](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions) if you are not familiar with them.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbe7441f-b5d8-4d6d-8971-343cc468f525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got all results [3.1419688, 3.1424613333333333, 3.138148] in 7.64s\n"
     ]
    }
   ],
   "source": [
    "# Use ray.get to return all the results at once, and it waits for the slowest task\n",
    "start = time.time()\n",
    "uneven_tasks = [\n",
    "    mc_pi_single_batch.remote(n)\n",
    "    for n in [10**7, 3*10**6, 10**6]\n",
    "]\n",
    "all_results = ray.get(uneven_tasks)\n",
    "print(f\"Got all results {all_results} in {time.time()-start:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57f12739-24b4-446c-92e4-e1cf9983678a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got results [3.140916] in 0.76s\n",
      "There are 2 tasks unfinished\n"
     ]
    }
   ],
   "source": [
    "# Instead, get the first finished task with ray.wait\n",
    "start = time.time()\n",
    "uneven_tasks = [\n",
    "    mc_pi_single_batch.remote(n)\n",
    "    for n in [10**7, 3*10**6, 10**6]\n",
    "]\n",
    "finished_tasks, unfinished_tasks = ray.wait(uneven_tasks)\n",
    "print(f\"Got results {ray.get(finished_tasks)} in {time.time()-start:.2f}s\")\n",
    "print(f\"There are {len(unfinished_tasks)} tasks unfinished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe36fd3c-155a-423d-8450-b1094034ae00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished tasks:\n",
      "  [ClientObjectRef(623b26bdd75b28e9ffffffffffffffffffffffff0100000001000000)]\n",
      "Unfinished tasks:\n",
      "  [ClientObjectRef(32cccd03c567a254ffffffffffffffffffffffff0100000001000000), ClientObjectRef(480a853c2c4c6f27ffffffffffffffffffffffff0100000001000000)]\n"
     ]
    }
   ],
   "source": [
    "# Remember that ray.wait always returns two lists of futures, and not the results themselves\n",
    "print(f\"Finished tasks:\\n  {finished_tasks}\")\n",
    "print(f\"Unfinished tasks:\\n  {unfinished_tasks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c37074e-65b2-4daa-acfa-d7137a9643f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got more results [3.1414092, 3.1416453333333334]\n",
      "There are now 0 tasks unfinished\n"
     ]
    }
   ],
   "source": [
    "# You can also wait for more than one task\n",
    "new_finished_tasks, new_unfinished_tasks = ray.wait(unfinished_tasks, num_returns=2)\n",
    "print(f\"Got more results {ray.get(new_finished_tasks)}\")\n",
    "print(f\"There are now {len(new_unfinished_tasks)} tasks unfinished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5fc105-8d5a-4f25-8366-a69eeeb9a648",
   "metadata": {},
   "source": [
    "### Combining ray.wait, while loops, and ray.cancel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26bb1e0-c475-4eb2-8845-93dfe3b7b3c6",
   "metadata": {},
   "source": [
    "Most often, `ray.wait` will be used in conjunction with a `while` loop like below.\n",
    "Most of the time this will wait until all tasks have finished, but in rare cases it may be useful to cancel remaining tasks with `ray.cancel`.\n",
    "In this case, we've included one very large batch we do not want to wait for.\n",
    "Watch the Ray Web UI while executing this cell to see the tasks in action.\n",
    "\n",
    "Canceling a task can result in \"unhandled errors\". As long as you know they came from purposefully canceling a task, and have written your tasks to have no harmful side effects if interrupted, they are benign.\n",
    "Without `force`, Ray will issue a `KeyboardInterrupt` and the error may look similar to what happens when interrupting a cell in a notebook.\n",
    "With `force`, the task will immediately exit and the error may simply say a worker has died.\n",
    "If the canceled task is still pending or is already finished, then there will be no error.\n",
    "\n",
    "Also notice how both `finished` and `unfinished` are always treated as lists, even if they contain only 1 task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32cb0cef-9442-4fd9-80fe-e943d061fe06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 1 results, 2 remaining, at 2.24s\n",
      "Have 2 results, 1 remaining, at 7.40s\n",
      "Canceling 1 unfinished tasks\n",
      "Final results: [3.1427573333333334, 3.1411512] in 7.40s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "unfinished = [\n",
    "    mc_pi_single_batch.remote(n)\n",
    "    for n in [10**10, 10**7, 3*10**6]\n",
    "]\n",
    "results = []\n",
    "while len(unfinished) > 1:\n",
    "    finished, unfinished = ray.wait(unfinished)\n",
    "    results.append(ray.get(finished[0]))\n",
    "    print(f\"Have {len(results)} results, {len(unfinished)} remaining, at {time.time()-start:.2f}s\")\n",
    "else:\n",
    "    print(f\"Canceling {len(unfinished)} unfinished tasks\")\n",
    "    for u in unfinished:\n",
    "        ray.cancel(u, force=True)\n",
    "print(f\"Final results: {results} in {time.time()-start:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396e12f0-0590-4b1d-8b9c-dec7714dea34",
   "metadata": {},
   "source": [
    "### Improved Pi approximation with task management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3180c76-8e31-488b-ba37-46bdf03f56ce",
   "metadata": {},
   "source": [
    "Now we can rewrite our Pi approximation example to make use of this more flexible task management, which allows us to do a few things:\n",
    "* Evaluate the accuracy of our Pi estimate as each task finishes\n",
    "* Launch a new task as soon as an old task finishes\n",
    "* Launch additional new tasks if the cluster scales up\n",
    "* Clean up any in-flight tasks that are no longer needed when we reach the desired accuracy.\n",
    "\n",
    "There are still a few simplifying assumptions here, such as requiring equal batch sizes.\n",
    "We also assume this is the only work happening on the cluster, and that we can fit exactly one task per node running in parallel.\n",
    "More robust code might use `ray.available_resources` instead of `ray.nodes`, and/or give the user some manual control over the degree of parallelism.\n",
    "\n",
    "We require the error to converge over multiple batches as a simple way to avoid the problem of low statistics leading to bad (under)estimates of the error in the first few batches.\n",
    "If you run this a few times, you may notice that this is not always effective!\n",
    "Improving the statistical rigor of the Pi simulation is not our goal in this tutorial, so we will let it slide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd17c7c6-de5d-4d01-9d34-5ce51b4b2727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smarter_approximate_pi_on_ray(batch_size=10**6, max_err=0.0005, convergence_req=5):\n",
    "    start = time.time()\n",
    "    pi_samples = []\n",
    "    # Initially, launch as many tasks as there are nodes in the cluster\n",
    "    unfinished_tasks = [\n",
    "        mc_pi_single_batch.remote(batch_size)\n",
    "        for _ in ray.nodes()\n",
    "    ]\n",
    "    # Initialize counters:\n",
    "    #  conv - how many times in a row the error is below max_err\n",
    "    #  N - how many batches have been processed total \n",
    "    conv, N = 0, 0\n",
    "    print(\"N    Pi       Err      STD      Conv  Elapsed(s)\")\n",
    "    while conv < convergence_req:\n",
    "        \n",
    "        # Get whichever task finishes first\n",
    "        finished_tasks, unfinished_tasks = ray.wait(unfinished_tasks)\n",
    "        N += 1\n",
    "        pi_samples.append(ray.get(finished_tasks[0]))\n",
    "        \n",
    "        # Calculate overall error on Pi; this assumes equal-sized batches!\n",
    "        pi = np.mean(pi_samples)\n",
    "        pi_std = np.std(pi_samples)\n",
    "        pi_err = pi_std / np.sqrt(N)\n",
    "        if pi_err < max_err:\n",
    "            conv += 1\n",
    "        else:\n",
    "            conv = 0\n",
    "        print(f\"{N:<4d} {pi:.6f} {pi_err:.6f} {pi_std:.6f} {conv:<5d} {time.time()-start:3.2f}\")\n",
    "        \n",
    "        # Start more tasks, checking the number of nodes again in case the cluster has scaled up\n",
    "        # Most of the time, we expect one available node, and don't want to clutter the output\n",
    "        n_avail_nodes = len(ray.nodes()) - len(unfinished_tasks)\n",
    "        if n_avail_nodes > 1:\n",
    "            print(f\"SCALE-UP: starting an additional {n_avail_nodes - 1} task(s) on new nodes\")\n",
    "        unfinished_tasks.extend([\n",
    "            mc_pi_single_batch.remote(batch_size)\n",
    "            for _ in range(n_avail_nodes)\n",
    "        ])\n",
    "    \n",
    "    else:\n",
    "        # Clean up leftover tasks\n",
    "        print(f\"Cleaning up {len(unfinished_tasks)} leftover tasks\")\n",
    "        for u in unfinished_tasks:\n",
    "            ray.cancel(u, force=True)\n",
    "    \n",
    "    return pi, pi_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db70a4db-e557-45dd-8fcf-745b4f3a105c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N    Pi       Err      STD      Conv  Elapsed(s)\n",
      "1    3.139072 0.000000 0.000000 1     0.75\n",
      "2    3.139536 0.000328 0.000464 2     0.76\n",
      "3    3.140664 0.000947 0.001640 0     0.80\n",
      "4    3.140535 0.000719 0.001437 0     1.54\n",
      "5    3.140654 0.000585 0.001307 0     1.55\n",
      "6    3.140731 0.000492 0.001206 1     1.57\n",
      "7    3.141217 0.000617 0.001633 0     2.36\n",
      "8    3.141002 0.000576 0.001630 0     2.37\n",
      "9    3.141125 0.000525 0.001575 0     2.37\n",
      "10   3.141235 0.000484 0.001530 1     3.11\n",
      "11   3.141332 0.000449 0.001491 2     3.12\n",
      "12   3.141586 0.000479 0.001658 3     3.12\n",
      "13   3.141645 0.000446 0.001606 4     3.84\n",
      "14   3.141553 0.000423 0.001583 5     3.87\n",
      "Cleaning up 3 leftover tasks\n",
      "DONE! Final result: pi = 3.1415528571428575 +/- 0.00042316864560587624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unhandled error (suppress with RAY_IGNORE_UNHANDLED_ERRORS=1): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Unhandled error (suppress with RAY_IGNORE_UNHANDLED_ERRORS=1): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n"
     ]
    }
   ],
   "source": [
    "pi, pi_err = smarter_approximate_pi_on_ray()\n",
    "print(f\"DONE! Final result: pi = {pi} +/- {pi_err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13c0445c-3786-4026-b2db-ad033f0f8c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try aiming for higher accuracy if you have autoscaling enabled to see it in action\n",
    "#pi, pi_err = smarter_approximate_pi_on_ray(batch_size=10**7, max_err=0.00005)\n",
    "#print(f\"DONE! Final result: pi = {pi} +/- {pi_err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea08cc54-5f1c-4a4e-bbb4-779570a76cc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ray Actors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0bab05-59f3-41d0-b8f3-523f5a7494d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "In addition to defining remote functions (i.e. Tasks), you can also define remote classes, which are called Actors.\n",
    "\n",
    "Before showing how actors work, it's important to mention that these won't be necessary for most users of Ray to make use of these.\n",
    "To quote [the docs](https://docs.ray.io/en/latest/ray-core/actors.html): \"\\[...\\] tasks are scheduled more flexibly, \\[and\\] if you don’t need the stateful part of an actor, you’re mostly better off using tasks\".\n",
    "We will show the basics here, and mention a few caveats about scheduling and worker behavior.\n",
    "However, you will be much more likely to interact with Actors indirectly through other libraries.\n",
    "\n",
    "Some things to keep in mind about Actors:\n",
    "* They are dedicated workers, and will execute only one task at a time.\n",
    "* There are a few common patterns involving Actors which we will not fully explore in this notebook, for example a [tree of actors](https://docs.ray.io/en/latest/ray-core/actors/patterns/tree-of-actors.html) with one \"Supervisor\" and some number of \"Workers\".\n",
    "* Typically, actors are automatically cleaned up when all references to them have gone out of scope, but they can also be cleaned up with `ray.kill()`.\n",
    "* Actors can be scheduled with specific resource requests. Tasks can also be scheduled this way, but unlike Tasks, Actors require 0 resources by default for *running*, and typically require more care in scheduling because they are long-lived.\n",
    "\n",
    "You can run the cells in this section immediately after the first two cells in this notebook (imports and initializing Ray).\n",
    "It does not rely on any cells in the Task Management section above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2196444e-8e57-4196-acb0-f2c985c94f51",
   "metadata": {},
   "source": [
    "### Creating, using, and cleaning up Actors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81b576d-274c-48cc-9e78-1ca8e7407845",
   "metadata": {},
   "source": [
    "Below, we create a worker for our Pi approximation that can run batch simlations of a given size.\n",
    "Note that both initializing the worker and subsequent calls to `run_batch` make use of `remote`.\n",
    "\n",
    "Watch the Ray Web UI to see the Actor lifecycle:\n",
    "* It appears as a dedicated worker on one of the nodes, labeled with the class name\n",
    "* It uses some CPU when running a simulation batch\n",
    "* It disappears after `ray.kill`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db864329-b896-4d76-b232-78076c6a17be",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class MCPiWorker:\n",
    "    def __init__(self, batch_size, worker_idx):\n",
    "        self.batch_size = batch_size\n",
    "        self.worker_idx = worker_idx\n",
    "    \n",
    "    def run_batch(self):\n",
    "        n_inside_quadrant = 0\n",
    "        for _ in range(self.batch_size):\n",
    "            x = random.uniform(0,1)\n",
    "            y = random.uniform(0,1)\n",
    "            if (x**2 + y**2) <= 1:\n",
    "                n_inside_quadrant += 1\n",
    "        pi = 4*n_inside_quadrant/self.batch_size\n",
    "        return pi, self.worker_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f558c46b-7018-4385-87e7-d4483b535d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClientActorHandle(7ad8a12a33cd39e588f5215501000000)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the worker, and note the type\n",
    "worker1 = MCPiWorker.remote(10**6, 1)\n",
    "print(worker1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd6d349c-986c-47bd-8f63-2b07a7d2ae66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting work on the Actor returns a future: ClientObjectRef(4e2ab276f14c37c27ad8a12a33cd39e588f521550100000001000000)\n",
      "Worker 1 returned a batch result pi=3.140976\n"
     ]
    }
   ],
   "source": [
    "# Run one batch of the pi simulation - very similar to using remote Tasks!\n",
    "pi_future = worker1.run_batch.remote()\n",
    "print(f\"Starting work on the Actor returns a future: {pi_future}\")\n",
    "pi, worker_id = ray.get(pi_future)\n",
    "print(f\"Worker {worker_id} returned a batch result pi={pi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86b993e3-295a-44e0-a837-d3a3932c05af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kill the worker\n",
    "ray.kill(worker1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a6f3e3-3896-428e-a22f-5a608ecf14b1",
   "metadata": {},
   "source": [
    "### Scheduling Actors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32909299-f12a-4c16-8a58-9530494e035e",
   "metadata": {},
   "source": [
    "If you try creating multiple workers at once, you may see them scheduled on the same node.\n",
    "This is not what we want for our current example - we don't want each batch of the simulation sharing single node resources!\n",
    "Let's check the time it takes to run two batches this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52dc008e-06c5-4d4b-9006-a66f79666b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Ray Web UI to see these (likely) appear on the same node\n",
    "worker2 = MCPiWorker.remote(10**7, 2)\n",
    "worker3 = MCPiWorker.remote(10**7, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "207ee8be-bb0e-4e97-85cd-d493ce8d83cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got results [(3.141006, 2), (3.1412604, 3)] in 7.51\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pi_futures = [\n",
    "    w.run_batch.remote()\n",
    "    for w in [worker2, worker3]\n",
    "]\n",
    "pi_results = ray.get(pi_futures)\n",
    "print(f\"Got results {pi_results} in {time.time()-start:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e7a78a9-e530-491b-b5ac-2d2f5bd1ce3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove these workers so we can try again\n",
    "ray.kill(worker2)\n",
    "ray.kill(worker3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5883b6-eb8e-471c-acb7-62bc6c21459b",
   "metadata": {},
   "source": [
    "To guarantee spreading out the Actors on different nodes, we'll make use of `options` for each worker.\n",
    "Specifying resource requirements can force the actors to be spread across nodes.\n",
    "The number of CPUs requested for this will depend on the Hardware Tier you choose for the cluster nodes.\n",
    "\n",
    "If every copy of the Actor needs the same resources, they can also be specified in the decorator we first used to turn our class into a Ray Actor.\n",
    "There is a lot more to scheduling that we won't cover here, and this is an area where Ray is adding functionality (especially in Ray 2.0), so be mindful of versions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbb5a2ad-ae1c-4030-bb98-8612dd235299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a resource request that will force Actors onto different nodes\n",
    "worker4 = MCPiWorker.options(num_cpus=1).remote(10**7, 4)\n",
    "worker5 = MCPiWorker.options(num_cpus=1).remote(10**7, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "777da0be-dc8d-482b-a839-86b2db2b24ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got results [(3.1423332, 4), (3.1413644, 5)] in 7.73\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pi_futures = [\n",
    "    w.run_batch.remote()\n",
    "    for w in [worker4, worker5]\n",
    "]\n",
    "pi_results = ray.get(pi_futures)\n",
    "print(f\"Got results {pi_results} in {time.time()-start:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b42e1357-bd31-4fa0-81e6-a73a8db6f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "ray.kill(worker4)\n",
    "ray.kill(worker5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ee2c0a-f35e-4b64-8460-c02581da8a12",
   "metadata": {},
   "source": [
    "### Complete Pi approximation with Actors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40fea49-9263-458a-9cc6-b0a683d51207",
   "metadata": {},
   "source": [
    "Below we've rewritten the Pi approximation function to use Actors instead of Tasks.\n",
    "Notice how we are manually keeping track of the worker ID for each Actor here, so we know which workers are idle and can accept more batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "856b4c4f-f2c0-44f7-a4ec-c568e31bde8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_pi_with_actors(batch_size=10**6, max_err=0.0005, convergence_req=5):\n",
    "    start = time.time()\n",
    "    pi_samples = []\n",
    "    n_workers = len(ray.nodes())\n",
    "    print(f\"Initializing {n_workers} workers\")\n",
    "    workers = [MCPiWorker.options(num_cpus=1).remote(batch_size, i) for i in range(n_workers)]\n",
    "    unfinished_tasks = [w.run_batch.remote() for w in workers]\n",
    "    conv, N = 0, 0\n",
    "    print(\"N    Pi       Err      STD      Conv  Elapsed(s)\")\n",
    "    while conv < convergence_req:\n",
    "        finished_tasks, unfinished_tasks = ray.wait(unfinished_tasks)\n",
    "        current_pi, idle_worker_idx = ray.get(finished_tasks[0])\n",
    "        N += 1\n",
    "        pi_samples.append(current_pi)\n",
    "        pi = np.mean(pi_samples)\n",
    "        pi_std = np.std(pi_samples)\n",
    "        pi_err = pi_std / np.sqrt(N)\n",
    "        print(f\"{N:<4d} {pi:.6f} {pi_err:.6f} {pi_std:.6f} {conv:<5d} {time.time()-start:3.2f}\")\n",
    "        if pi_err < max_err:\n",
    "            conv += 1\n",
    "        else:\n",
    "            conv = 0\n",
    "        unfinished_tasks.append(workers[idle_worker_idx].run_batch.remote())\n",
    "    else:\n",
    "        print(f\"Cleaning up {len(workers)} workers ({len(unfinished_tasks)} with leftover tasks)\")\n",
    "        for w in workers:\n",
    "            ray.kill(w)\n",
    "    return pi, pi_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce30b7cf-25ff-4160-b1f8-182034df830e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing 3 workers\n",
      "N    Pi       Err      STD      Conv  Elapsed(s)\n",
      "1    3.139984 0.000000 0.000000 0     1.46\n",
      "2    3.140812 0.000585 0.000828 1     1.48\n",
      "3    3.141051 0.000436 0.000756 0     1.49\n",
      "4    3.141045 0.000327 0.000654 1     2.22\n",
      "5    3.141002 0.000265 0.000592 2     2.23\n",
      "6    3.141135 0.000252 0.000616 3     2.24\n",
      "7    3.141265 0.000247 0.000653 4     2.98\n",
      "Cleaning up 3 workers (3 with leftover tasks)\n",
      "DONE! Final result: pi = 3.1412651428571428 +/- 0.0002469189265087082\n"
     ]
    }
   ],
   "source": [
    "pi, pi_err = approximate_pi_with_actors()\n",
    "print(f\"DONE! Final result: pi = {pi} +/- {pi_err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77001034-3bee-47c8-8e40-7e74050c3e2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Object store and ray.put"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97bf9c3-c50a-4f0b-8d69-c6d01b77ff4b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Until now, we have been running simulations that generate and discard one point at a time.\n",
    "They have been CPU-intensive, but use almost no RAM.\n",
    "\n",
    "Most applications for Ray will involve processing existing data, often large amounts of it.\n",
    "What happens when we mimic that scenario by generating random points in advance, then passing them to a remote task?\n",
    "Ray will complain about the large amount of data being passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "855d45e3-b7ed-4177-b665-b4380068a1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-generate the points\n",
    "points = np.random.uniform(size=(2, 10**6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6ca862d-ea39-4b54-b821-b394b8870025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new streamlined remote function to process them and estimate pi\n",
    "@ray.remote\n",
    "def mc_pi(points):\n",
    "    n_inside = sum(points[0]**2 + points[1]**2 < 1)\n",
    "    n_samples = points.shape[1]\n",
    "    return 4 * n_inside / n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90331e6-3ed8-44af-bcd0-91aaf5c6c73f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "In general, it is more efficient to pass data around the Ray cluster by first loading it into the [Object Store](https://docs.ray.io/en/latest/ray-core/objects.html).\n",
    "Then, pass it to Tasks via **object refs**.\n",
    "\n",
    "Both Tasks and Actors already return object refs; let's summarize their properties:\n",
    "* Objects are stored in the shared-memory object store. There is one object store per node, and memory usage of the object store is shown in the Plasma column of the Ray Web UI.\n",
    "* Objects are referred to by object refs, a unique pointer or ID that are used to refer to objects without seeing the actual data.\n",
    "* Remote function calls automatically return object refs, in which case they are essentially futures. The contents of the object are accessed using `ray.get`.\n",
    "\n",
    "Now we want to introduce some **new** properties and ways to use object refs:\n",
    "* You can also explicitly create object refs using `ray.put`.\n",
    "* When object refs are passed as arguments to a remote function, they are automatically de-referenced inside the function (no need to explicitly call `ray.get`). This does not apply to object refs nested inside other arguments.\n",
    "* Remote objects are **immutable**\n",
    "\n",
    "Watch the Plasma store usage in the Ray Web UI while running this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13edd6a2-95d6-4752-a9c0-92eefa23c9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspect the type of the argument we are passing: <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ray/util/client/worker.py:501: UserWarning: More than 10MB of messages have been created to schedule tasks on the server. This can be slow on Ray Client due to communication overhead over the network. If you're running many fine-grained tasks, consider running them inside a single remote function. See the section on \"Too fine-grained tasks\" in the Ray Design Patterns document for more details: https://docs.google.com/document/d/167rnnDFIVRhHhK4mznEIemOtj63IOhtIPvSYaPgI4Fg/edit#heading=h.f7ins22n6nyl. If your functions frequently use large objects, consider storing the objects remotely with ray.put. An example of this is shown in the \"Closure capture of large / unserializable object\" section of the Ray Design Patterns document, available here: https://docs.google.com/document/d/167rnnDFIVRhHhK4mznEIemOtj63IOhtIPvSYaPgI4Fg/edit#heading=h.1afmymq455wu\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got results 3.140376 in 3.26s\n"
     ]
    }
   ],
   "source": [
    "# First, pass the points directly to the function - notice the warning the first time you run this!\n",
    "start = time.time()\n",
    "print(f\"Inspect the type of the argument we are passing: {type(points)}\")\n",
    "pi = ray.get(mc_pi.remote(points))\n",
    "print(f\"Got results {pi} in {time.time()-start:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ceb890b-a3ee-4b0c-b80a-663f71a5ec07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspect the type of the argument we are passing: <class 'ray._raylet.ClientObjectRef'>\n",
      "Got results 3.140376 in 2.15s\n"
     ]
    }
   ],
   "source": [
    "# Now, use ray.put to load the points into the object store, and pass only the reference\n",
    "# Notice that there is no need to add any \"ray.get\" into our function code!\n",
    "start = time.time()\n",
    "points_ref = ray.put(points)\n",
    "print(f\"Inspect the type of the argument we are passing: {type(points_ref)}\")\n",
    "pi = ray.get(mc_pi.remote(points_ref))\n",
    "print(f\"Got results {pi} in {time.time()-start:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdacad5-1d1c-4d79-a2d3-d3d66a320899",
   "metadata": {},
   "source": [
    "Explicitly loading the points into the object store before calling the function is a little faster.\n",
    "The real benefits to passing references like this are in two situations:\n",
    "* If multiple remote tasks will operate on the same data, using `ray.put` means it has to be copied into the object store only once instead of every time it is passed to a function.\n",
    "* If data is generated as a result of another remote task, then fed into a subsequent task, there is no need to call `ray.get` in between, and the data need never leave the cluster. In fact, calling `ray.get` unnecessarily is listed as a [common antipattern](https://docs.ray.io/en/latest/ray-core/tasks/patterns/unnecessary-ray-get.html).\n",
    "\n",
    "To see an example of the second case, we can have a remote task generate our points rather than generating them here in the client notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13239dc8-2cd8-4c8f-a217-c4430a158546",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def mc_pi_generate_points(n_samples):\n",
    "    points = np.random.uniform(size=(2, n_samples))\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3af7ba36-2598-40b1-a42c-5d377361326e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspect the type of the argument we are passing: <class 'ray._raylet.ClientObjectRef'>\n",
      "Got results 3.140308 in 2.04s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "n = 10**6\n",
    "points_future = mc_pi_generate_points.remote(n)\n",
    "print(f\"Inspect the type of the argument we are passing: {type(points_future)}\")\n",
    "pi = ray.get(mc_pi.remote(points_future))\n",
    "print(f\"Got results {pi} in {time.time()-start:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504d8aab-efdf-46a1-9732-60707526ced8",
   "metadata": {
    "tags": []
   },
   "source": [
    "Note that numpy arrays are especially efficient for use in the Ray object store:\n",
    "The [docs](https://docs.ray.io/en/releases-2.0.0/ray-core/objects.html) note that \n",
    "\"If the object is a numpy array or a collection of numpy arrays, the get call is zero-copy and returns arrays backed by shared object store memory. Otherwise, we deserialize the object data into a Python object.\"\n",
    "In other words, if a remote task is acting on a numpy array that is already in the corresponding node's object store, it can act directly on the array without making another copy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7dd185-c657-4b63-bcd5-257d5d5c4deb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading large data with Ray Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d556f68c-0bf9-4d2d-8d97-c152b25f6448",
   "metadata": {
    "tags": []
   },
   "source": [
    "Dealing directly with `ray.put` may be simple and efficient with our example numpy arrays, but most problems will start with some data (potentially large) living in files on disk.\n",
    "Ideally, we should avoid reading that data into the client notebook at all, and read it directly into the object store of the Ray cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a1183a-19a2-47cc-9eaa-3420d2f06663",
   "metadata": {},
   "source": [
    "### Exploring the available data files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13928dd-4ab1-4652-a1be-ad3fc2f0365b",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this section, we will read in pre-generated points stored as parquet files.\n",
    "The code to generate these files is in the `admin-notebooks`, and the recommended way to access the files during a workshop is to mount a **Dataset** from the public version of this project which contains those files.\n",
    "\n",
    "Adjust the path below to match where the files are located in your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31ed3bac-1add-48a0-a773-3cb3cecb1029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = f\"/domino/datasets/local/{os.environ['DOMINO_PROJECT_NAME']}\"\n",
    "# dataset_path = \"/domino/datasets/local/Points-For-Pi-Approximation\"\n",
    "# dataset_path = \"/domino/datasets/Points-For-Pi-Approximation\"\n",
    "dataset_path = \"/mnt/imported/data/Points-For-Pi-Approximation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631859f2-782c-4a5f-9c91-b828c81f564b",
   "metadata": {},
   "source": [
    "Ensure the files are present as expected.\n",
    "Each file shows how many points are represented in exponential notation, e.g. `3e3` for `300`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5ae2eb7-06de-4a86-b8a6-0e95c1575a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5G points_1e8.parquet\n",
      "459M points_3e7.parquet\n",
      "154M points_1e7.parquet\n",
      " 47M points_3e6.parquet\n",
      " 16M points_1e6.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -shS {dataset_path} | grep parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efb7988-2650-4f50-8b0b-0a603aeee9fc",
   "metadata": {},
   "source": [
    "We also expect some directories with split parquet files, which also indicate the number of individual files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd57fd93-adb1-47e2-94bc-23a61a4c09f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6G\t/domino/datasets/local/ray-tutorial/points_1e8_split10\n",
      "478M\t/domino/datasets/local/ray-tutorial/points_3e7_split10\n",
      "4.7G\t/domino/datasets/local/ray-tutorial/points_3e8_split30\n"
     ]
    }
   ],
   "source": [
    "!du -sh {dataset_path}/points_*_split*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc298309-47fe-4f94-8b2d-c28348f7fbab",
   "metadata": {},
   "source": [
    "### Reading in parquet files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c6cb0b-693e-4f6a-aef9-a0dcbc28b607",
   "metadata": {},
   "source": [
    "To read a parquet file with Ray Data, simply use the `ray.data.read_parquet` function.\n",
    "Watch the RAM and Plasma usage when reading in the files.\n",
    "These cells assume Small hardware tier for the cluster, and pick \"small\" and \"medium\" files accordingly - you may want to experiment with different sizes on different hardware tiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1e533ea-8dd1-477a-a284-a450a80af8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_points_ds = ray.data.read_parquet(os.path.join(dataset_path, \"points_1e6.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7eb1c4fa-464c-492d-bb48-3364481cef7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 0.15744372219962044, 'y': 0.9991738982470619}\n",
      "{'x': 0.24704316132542592, 'y': 0.6131349061935508}\n",
      "{'x': 0.443876643349869, 'y': 0.9617571214294107}\n"
     ]
    }
   ],
   "source": [
    "small_points_ds.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78b0fd7b-97d0-44f0-9b27-3dc2dc07649c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ray.data.dataset.Dataset"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(small_points_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "985bf11b-2451-416f-bb64-4ec8adf51516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small data has 1000000 rows.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Small data has {small_points_ds.count()} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931a1f92-f826-4785-be9e-07e349e46474",
   "metadata": {},
   "source": [
    "### Iterating over data with map and map_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48542178-2b2c-4d5f-8082-ad400fdb04ea",
   "metadata": {},
   "source": [
    "To process these points, we have two major options with Ray Data:\n",
    "* Loop over each row individually with `map`\n",
    "* Loop over batches with `map_batches`\n",
    "\n",
    "In general, `map_batches` is much more efficient.\n",
    "It can operate on the data as a pyarrow Table, or as a pandas Dataframe, using vectorized operations.\n",
    "Using `map_batches` does typically require some extra care in the formatting of input and output data - note the comments in the below cells!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7baa2b06-117e-4b60-8e6a-fdcda9dd8cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map Progress: 100%|██████████| 1/1 [00:09<00:00,  9.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspect the intermediate boolean results:\n",
      " <class 'ray.data.dataset.Dataset'>\n",
      "False\n",
      "True\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GroupBy Map: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "GroupBy Reduce: 100%|██████████| 1/1 [00:00<00:00, 93.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspect the intermediate sum results:\n",
      " <class 'int'>\n",
      "Pi is approximately 3.14048 (from 1000000 samples in 11.00s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Map individual rows\n",
    "start = time.time()\n",
    "n_total = small_points_ds.count()\n",
    "inside = small_points_ds.map(lambda row: (row['x']**2 + row['y']**2) < 1 )\n",
    "\n",
    "print(f\"Inspect the intermediate boolean results:\\n {type(inside)}\")\n",
    "inside.show(3)\n",
    "inside.schema()\n",
    "\n",
    "n_inside = inside.sum()\n",
    "print(f\"Inspect the intermediate sum results:\\n {type(n_inside)}\")\n",
    "\n",
    "pi = 4 * n_inside / n_total\n",
    "print(f\"Pi is approximately {pi} (from {n_total} samples in {time.time()-start:.2f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "30889054-1f78-47ea-be87-a3a7a00caba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process a batch.\n",
    "# It will expect a pandas Dataframe as input, which we can specify in the next cell\n",
    "# It must return a pandas Dataframe or pyarrow Table as output\n",
    "# (This is true even if the output will be a single number!)\n",
    "\n",
    "import pyarrow as pa\n",
    "\n",
    "def process_batch(batch):\n",
    "    result = (batch['x']**2 + batch['y']**2 < 1).sum()\n",
    "    return pa.Table.from_pydict({\"n_inside\": [result]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc8e42fa-de0f-4a26-81a2-c7e84fb1111e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map Progress: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspect the intermediate sum results:\n",
      " <class 'ray.data.dataset.Dataset'>\n",
      "{'n_inside': 785120}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GroupBy Map: 100%|██████████| 1/1 [00:00<00:00, 429.22it/s]\n",
      "GroupBy Reduce: 100%|██████████| 1/1 [00:00<00:00, 392.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi is approximately 3.14048 (from 1000000 samples in 0.29s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "n_total = small_points_ds.count()\n",
    "n_inside = small_points_ds.map_batches(process_batch,batch_format='pandas')\n",
    "\n",
    "print(f\"Inspect the intermediate sum results:\\n {type(n_inside)}\")\n",
    "n_inside.show(3)\n",
    "n_inside.schema()\n",
    "\n",
    "pi = 4 * n_inside.sum() / n_total\n",
    "print(f\"Pi is approximately {pi} (from {n_total} samples in {time.time()-start:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a7bc2-944b-41e7-85e6-c843e6ba176f",
   "metadata": {},
   "source": [
    "If you are watching the Ray Web UI, you will notice all the computation happening on a single node in the previous cells.\n",
    "We are incurring overhead to do the computation in Ray, without any of the benefits.\n",
    "In fact, using pure pandas is much faster than what we've been doing with Ray!\n",
    "This is a good example of the principle that you should not distribute your code unless there is a real need to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b73c6723-bfd1-496b-81de-a05843bc7d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure pandas comparison of previous section - it's actually faster!\n",
    "import pandas as pd\n",
    "\n",
    "small_points_df = pd.read_parquet(os.path.join(dataset_path, \"points_1e6.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "51dd419e-a42b-4bd9-aa5c-53aa54c788be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi is approximately 3.14048 (from 1000000 samples in 0.01s)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "n_total = small_points_df.shape[0]\n",
    "n_inside = (small_points_df['x']**2 + small_points_df['y']**2 < 1).sum()\n",
    "pi = 4 * n_inside / n_total\n",
    "print(f\"Pi is approximately {pi} (from {n_total} samples in {time.time()-start:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e64ae8-a9b7-464c-9c7e-40aac06dbb0f",
   "metadata": {},
   "source": [
    "### Multiple blocks and partial reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1430e6ac-9ff2-4179-83c6-1ad899a09497",
   "metadata": {},
   "source": [
    "To get data on multiple nodes, we can repartition the data like below.\n",
    "\n",
    "However, the real benefits of loading data directly into Ray (instead of, say, loading it here in the client notebook and then using `ray.put`) come when data is much larger - too large to easily load onto any single node.\n",
    "\n",
    "With Ray Data, when we read in data that is already broken into multiple files, it will automatically partition it across nodes when doing computations.\n",
    "The level of parallelism on file read defaults to 200 OR the number of individual parquet files, **whichever is smaller**.\n",
    "This means that Ray Data is not well suited for reading in large monolithic parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb512176-09e6-449f-b5a4-90cbaa8d9cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_points_ds.num_blocks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a137d886-fb74-4dda-8c3e-c4db8c4dcb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repartition: 100%|██████████| 3/3 [00:00<00:00,  4.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# Repartition the small data\n",
    "small_points_ds = small_points_ds.repartition(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9db3148-1e19-47ee-b2a2-4e7a76d483fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_points_ds.num_blocks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46f67899-72f8-4b46-892c-87d7d9fc30d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the medium data, which is already split among multiple files\n",
    "medium_points_ds = ray.data.read_parquet(os.path.join(dataset_path, \"points_1e8_split10\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db7be14f-42ce-416c-be15-4b2f72d9608a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 0.37296319431756686, 'y': 0.3874623725627472}\n",
      "{'x': 0.6090430917019034, 'y': 0.15193178219888936}\n",
      "{'x': 0.028662288104923106, 'y': 0.6215241597148781}\n"
     ]
    }
   ],
   "source": [
    "medium_points_ds.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c05a2d25-6fd0-43dd-ae0a-8ccbc680362b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_points_ds.num_blocks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ed27d8-c6db-4497-95de-79f8076b1514",
   "metadata": {},
   "source": [
    "When reading in multiple parquet files, Ray Data will generally read only the first file until necessary.\n",
    "This is an example of **lazy execution**, which is in contrast to the **immediate execution** we have seen with Ray so far.\n",
    "Watch the Ray Web UI to see how the Plasma memory usage has not increased much yet, but will go up when we actually need to transform the entire data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bbc27872-0ab6-4ca3-9a8d-a193afce6fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parquet files have some metadata already available without needing to read all the files.\n",
    "medium_points_ds.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c2215de7-cbe2-4c45-a875-20916f660a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map Progress: 100%|██████████| 10/10 [00:02<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspect the intermediate sum results:\n",
      " <class 'ray.data.dataset.Dataset'>\n",
      "{'n_inside': 7853759}\n",
      "{'n_inside': 7853820}\n",
      "{'n_inside': 7852750}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GroupBy Map: 100%|██████████| 10/10 [00:00<00:00, 416.36it/s]\n",
      "GroupBy Reduce: 100%|██████████| 1/1 [00:00<00:00, 333.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi is approximately 3.14153152 (from 100000000 samples in 6.41s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Watch the object store memory go up as the rest of the medium dataset gets read in!\n",
    "start = time.time()\n",
    "n_total = medium_points_ds.count()\n",
    "n_inside = medium_points_ds.map_batches(process_batch,batch_format='pandas')\n",
    "\n",
    "print(f\"Inspect the intermediate sum results:\\n {type(n_inside)}\")\n",
    "n_inside.show(3)\n",
    "n_inside.schema()\n",
    "\n",
    "pi = 4 * n_inside.sum() / n_total\n",
    "print(f\"Pi is approximately {pi} (from {n_total} samples in {time.time()-start:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d4fa5c-118a-4496-adad-54c5ba555f8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Memory overflows and other bonus activities\n",
    "\n",
    "We've seen a few basic applications of Ray Data, but we have not demonstrated the ways things can go *wrong*.\n",
    "\n",
    "One of the most common problem is memory overflows - any time a single parquet file is too large to read in on a single machine, Ray Data will generate errors somewhat like the below:\n",
    "\n",
    "```\n",
    "ConnectionError: GRPC connection failed: <_InactiveRpcError of RPC that terminated with:\n",
    "\tstatus = StatusCode.NOT_FOUND\n",
    "\tdetails = \"Failed to serialize response!\"\n",
    "\tdebug_error_string = \"{\"created\":\"@1664232188.123154377\",\"description\":\"Error received from peer ipv4:172.20.98.49:10001\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1074,\"grpc_message\":\"Failed to serialize response!\",\"grpc_status\":5}\"\n",
    "```\n",
    "\n",
    "These can be very hard to interpret unless you know what you are looking for, and/or you see the memory run up to the max while you are watching in the Ray Web UI.\n",
    "Data can also take several times the memory footprint than you might expect from seeing the size on disk - notice how much was required for the `medium` dataset in this notebook.\n",
    "\n",
    "Try reading in the single medium dataset like below to see this problem first-hand.\n",
    "If you do, pay attention to what happens if you try to run additional ray code afterwards.\n",
    "Because your connection to the cluster crashes, ray is no longer initialized!\n",
    "If you run more ray code after this, ray will implicitly do a `ray.init()` to re-establish a cluster connection... however, that wil **not** be the correct connection to the Domino cluster.\n",
    "(Remember the correct way to do `ray.init()` involves referencing the Domino-provided cluster address.)\n",
    "When in doubt, restarting the workspace will fully reset the cluster and allow you to connect again the correct way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6f436d09-32e5-494e-90de-f8401a0fc078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#medium_monolith_points_ds = ray.data.read_parquet(os.path.join(dataset_path, \"points_1e8.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0da7c8b1-1111-40ef-b255-f6e6a0567a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#medium_monolith_points_ds.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d815b423-eeeb-4981-9125-3b130aba7160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ray.is_initialized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8bdfe692-5d32-42c6-afec-e0e9b766c137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ray.nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583d6a43-27f5-436b-a838-edae3513feb7",
   "metadata": {},
   "source": [
    "Ray Data is not designed to supplant generic ETL tools like spark - see their [FAQ](https://docs.ray.io/en/latest/data/faq.html) for some more commentary.\n",
    "It is mostly useful as an efficient way to load and pass data to other Ray libraries, so we won't go into any more detail in this tutorial.\n",
    "However, if you find yourself needing to do some last-mile preprocessing with Ray Data, you may want to return to this example notebook and see what happens when you make some of the following change to code in this section:\n",
    "* Try to return something that is NOT a table or dataframe from a function given to `map_batches` - see what error results.\n",
    "* Return a pandas Dataframe instead of a pyarrow table, and see how the resulting `ds.schema()` changes.\n",
    "* Try to do math like `batch['x']**2` inside a function given to `map_batches` without specifying `batch_format='pandas'`, i.e. directly on a pyarrow table - see what error results.\n",
    "* Run the cells in this section on larger data to really see the performance differences among the different methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c5716d-80fa-4d24-9284-1dbff374edb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading large data with Modin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d36285-ca67-4014-a259-a8b27743d68a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Unlike Ray Data, [Modin](https://modin.readthedocs.io/en/stable/) is meant to be a drop-in replacement for Pandas that can seamlessly handle large data with a Ray cluster as the backend.\n",
    "It does not have 100% coverage of the Pandas API, but where it does have coverage it aims for complete compatibility - simply replace `import pandas as pd` with `import modin.pandas as pd`!\n",
    "\n",
    "To facilitate experimenting with both, we will instead import modin as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c5f33ab-fe31-4cd1-8a69-67755743949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modin\n",
    "import modin.pandas as mpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a58af4c-27ae-45ea-aed8-33ac9f5e8e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PandasOnRay'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that Modin is using Ray\n",
    "modin.utils.get_current_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe937daf-272b-44a7-b329-9431041999d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = f\"/domino/datasets/local/{os.environ['DOMINO_PROJECT_NAME']}\"\n",
    "#dataset_path = \"/domino/datasets/local/Points-For-Pi-Approximation\"\n",
    "#dataset_path = \"/domino/datasets/Points-For-Pi-Approximation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c7065c-4ac9-432b-b416-57d3f26653d6",
   "metadata": {},
   "source": [
    "### Reading in parquet files and manipulating data\n",
    "\n",
    "Reading in parquet files - or any other format - is identical to Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d20ddf68-8f3a-49dc-a377-fd30362e30f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_points_mdf = mpd.read_parquet(os.path.join(dataset_path, \"points_1e6.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3560b55d-7bdc-4699-9ad7-e0b1946adfeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.157444</td>\n",
       "      <td>0.999174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.247043</td>\n",
       "      <td>0.613135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.443877</td>\n",
       "      <td>0.961757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y\n",
       "0  0.157444  0.999174\n",
       "1  0.247043  0.613135\n",
       "2  0.443877  0.961757"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_points_mdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9e69f12-a4dd-4425-8ede-46ad1d8d2974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modin.pandas.dataframe.DataFrame"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(small_points_mdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1c0dae8f-88bd-4d62-926e-c8fb620900fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_points_inside = small_points_mdf['x']**2 + small_points_mdf['y']**2 < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "532fae5b-a616-4d8f-9aca-48da43809db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modin.pandas.series.Series"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(small_points_inside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cb9b089c-3d64-40ee-89c9-ff3aab1e05f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "785120"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(small_points_inside)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474a4ac8-63a7-45bd-9f49-e49ded74c81b",
   "metadata": {},
   "source": [
    "### Parallel reads with Modin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c039d43-713f-4b2d-adb9-9c4850f6d63e",
   "metadata": {},
   "source": [
    "Modin can read single large parquet files even if they do not fit in a single node's memory - however, it is not always robust to a \"messy\" cluster with some memory already in use.\n",
    "Running the below cells in the same session as all the preceding notebook sections will likely result in an error, so to see Modin in action with larger data restart the workspace first.\n",
    "(Remember to initialize the Ray cluster correctly before skipping to this section!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "91d0dbf3-1495-47aa-9e19-75f099699c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the larger data\n",
    "medium_points_mdf = mpd.read_parquet(os.path.join(dataset_path, \"points_1e8.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2e21f211-8fa4-4561-836a-12f813e40b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi is approximately 3.14153468 (from 100000000 samples in 12.04s)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "n_total = medium_points_mdf.shape[0]\n",
    "n_inside = sum(medium_points_mdf['x']**2 + medium_points_mdf['y']**2 < 1)\n",
    "pi = 4 * n_inside / n_total\n",
    "print(f\"Pi is approximately {pi} (from {n_total} samples in {time.time()-start:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f0ecd3-12f9-43db-83da-38ad924d8a05",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Common pitfalls for large data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66657176-794d-433b-8c42-bdc749c0ecf8",
   "metadata": {},
   "source": [
    "To summarize and expand on what we've seen in the previous sections, here are a few good general practices:\n",
    "1. Avoid copying data to and from the cluster unnecessarily - use `ray.put` and delay using `ray.get` where appropriate when dealing with Ray Core functionality.\n",
    "2. Remote tasks and actors cannot access files in `/mnt`, but they can access files mounted via `/domino/datasets/`, so store large files in Datasets.\n",
    "3. Watch the Ray Web UI to see whether memory usage (especially RAM) are close to the limit. If code is running correctly, high memory usage is no problem - Ray will usually try to **spill to disk** when needed. But if code is seeing errors, and memory usage is high, try running on a smaller subset of data for initial troubleshooting.\n",
    "4. Ray Data can only parallelize data read up to the number of individual parquet files being read, and it usually requires several times the on-disk size in memory. Split data into smaller individual files to prepare for reading with Ray Data.\n",
    "5. Modin can parallelize data read even for single large files, but is not always robust to a \"messy\" cluster. Read data into Modin early in the script with a \"fresh\" workspace and cluster.\n",
    "6. Any time a large data operation kills cluster workers and causes an error, beware the fact that it also likely kills the cluster connection. Even if subsequent ray code seems to run, it may have implicitly run an incorrect `ray.init()` to restart the connection without pointing to the correct Domino cluster address. Check `ray.is_initialized()`, `ray.nodes()` or similar to verify whether you are correctly connected to your Domino cluster, and when in doubt restart the workspace entirely.\n",
    "\n",
    "In practice, the best way to load and manipulate large data in Ray will depend heavily on what other packages and libraries you plan to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd916e9-81be-4b04-8d97-f032a68938c5",
   "metadata": {},
   "source": [
    "## Bonus - performance improvements with dedicated local storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c707554-2014-47fb-b0ea-2c0689a704e0",
   "metadata": {},
   "source": [
    "We've just alluded to the fact that Ray will **spill to disk** when the object store memory is full.\n",
    "This is an incredibly useful mechanism that allows manipulating data even when the total data size is too large to fit in the entire cluster's memory.\n",
    "But how do you know when this is happening, and how does it work?\n",
    "\n",
    "First, inspect the folder where spilled objects will be put - this will give an error if nothing has been spilled to disk, but should show more files as larger data is read in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ca88d3f3-f0d9-490d-a598-7d242816cb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def ray_local_file_ls(path):\n",
    "    print(os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "be64dfe5-45b3-4db7-8315-d2c6e027ec76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unhandled error (suppress with RAY_IGNORE_UNHANDLED_ERRORS=1): \u001b[36mray::ray_local_file_ls()\u001b[39m (pid=778, ip=10.0.46.72)\n",
      "  File \"/tmp/ipykernel_1584/3441348648.py\", line 3, in ray_local_file_ls\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/ray/session_latest/ray_spilled_objects'\n",
      "Unhandled error (suppress with RAY_IGNORE_UNHANDLED_ERRORS=1): \u001b[36mray::ray_local_file_ls()\u001b[39m (pid=2234, ip=10.0.46.72)\n",
      "  File \"/tmp/ipykernel_1584/3441348648.py\", line 3, in ray_local_file_ls\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/ray/session_latest/ray_spilled_objects'\n",
      "Unhandled error (suppress with RAY_IGNORE_UNHANDLED_ERRORS=1): \u001b[36mray::ray_local_file_ls()\u001b[39m (pid=583, ip=10.0.46.72)\n",
      "  File \"/tmp/ipykernel_1584/3441348648.py\", line 3, in ray_local_file_ls\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/ray/session_latest/ray_spilled_objects'\n"
     ]
    }
   ],
   "source": [
    "# List files in the spilled objects folder on each node\n",
    "[ray_local_file_ls.remote(\"/tmp/ray/session_latest/ray_spilled_objects\") for _ in ray.nodes()];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302dc331-6417-42de-9258-8cbb7faa1894",
   "metadata": {},
   "source": [
    "Second, inspect the total disk usage of the local filesystem.\n",
    "Compare the results of this with and without dedicated local storage - you'll notice the space is probably larger and more used without the dedicated local storage!\n",
    "This is because each Ray node is always given a `/tmp` folder to work with, and by default it is mounted from the same storage used by Domino Datasets.\n",
    "\n",
    "If you enable local storage, this will show exactly the amount of storage you request, and the `/tmp` folder be located on the **local disk** of the node - meaning it gets better IO performance.\n",
    "This is especially true if the shared Datasets storage is heavily used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ff34ee0-623e-459f-bd2c-c85a2a53b84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "@ray.remote\n",
    "def ray_disk_usage(path):\n",
    "    time.sleep(1)\n",
    "    usage = shutil.disk_usage(path)\n",
    "    print(f\"{usage.used/(1024**3):.4f} of {usage.total/(1024**3):.4f}G used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a0a33269-8a27-4bad-9024-f36da5f3c2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ray_disk_usage pid=583)\u001b[0m 26.2702 of 999.9883G used\n",
      "\u001b[2m\u001b[36m(ray_disk_usage pid=770)\u001b[0m 26.2702 of 999.9883G used\n",
      "\u001b[2m\u001b[36m(ray_disk_usage pid=2233)\u001b[0m 26.2702 of 999.9883G used\n"
     ]
    }
   ],
   "source": [
    "# Show the disk usage for each node\n",
    "[ray_disk_usage.remote(\"/tmp/ray\") for _ in ray.nodes()];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ffcf8a-9870-42ff-93af-fb8b96753b61",
   "metadata": {},
   "source": [
    "We can benchmark a large data operation with and without local storage to see the difference.\n",
    "The below few cells can be run without running any previous cells in the notebook.\n",
    "See if you get similar results as the test run of this notebook:\n",
    "* 58.40s without local storage\n",
    "* 48.24s with local storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d8eeb5df-dd31-4234-b5ad-6e16a462956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import modin.pandas as mpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b9cb12d0-e4e4-4a9f-ad22-deb37ab0d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ray.is_initialized() == False:\n",
    "    service_host = os.environ[\"RAY_HEAD_SERVICE_HOST\"]\n",
    "    service_port = os.environ[\"RAY_HEAD_SERVICE_PORT\"]\n",
    "    ray.init(f\"ray://{service_host}:{service_port}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cfa3646e-236f-4206-adda-dfaa149070f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = f\"/domino/datasets/local/{os.environ['DOMINO_PROJECT_NAME']}\"\n",
    "#dataset_path = \"/domino/datasets/local/Points-For-Pi-Approximation\"\n",
    "#dataset_path = \"/domino/datasets/Points-For-Pi-Approximation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "104f87d2-01cd-4f5b-bf7c-98562cd13add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "\n",
    "def process_batch(batch):\n",
    "    result = (batch['x']**2 + batch['y']**2 < 1).sum()\n",
    "    return pa.Table.from_pydict({\"n_inside\": [result]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dc2b9540-1e6f-4e41-bb52-9db252660b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata Fetch Progress: 100%|██████████| 5/5 [00:00<00:00, 65.30it/s]\n",
      "Map Progress: 100%|██████████| 30/30 [00:02<00:00, 10.54it/s]\n",
      "GroupBy Map: 100%|██████████| 30/30 [00:00<00:00, 297.29it/s]\n",
      "GroupBy Reduce: 100%|██████████| 1/1 [00:00<00:00, 167.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi is approximately 3.1417218933333335 (from 300000000 samples in 11.47s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "large_points_ds = ray.data.read_parquet(os.path.join(dataset_path, \"points_3e8_split30\"))\n",
    "n_total = large_points_ds.count()\n",
    "n_inside = large_points_ds.map_batches(process_batch,batch_format='pandas')\n",
    "pi = 4 * n_inside.sum() / n_total\n",
    "print(f\"Pi is approximately {pi} (from {n_total} samples in {time.time()-start:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbf7093-4cf4-4572-9935-3e0d7ded8c4e",
   "metadata": {},
   "source": [
    "Smaller data results show about the same time for each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacea34c-a90c-475c-8349-18bc48a52988",
   "metadata": {},
   "source": [
    "### Congratulations!\n",
    "\n",
    "You have finished the Intermediate tutorial (part 1), where we covered the following:\n",
    "* More options for remote Task management with ray.wait and ray.cancel\n",
    "* Creating and scheduling remote Actors\n",
    "* Using the Ray object store with ray.put\n",
    "* Loading and processing data with Ray Data\n",
    "* Loading and processing data with Modin\n",
    "* Common pitfalls for larger-than-memory data\n",
    "* Bonus - performance improvements with dedicated local storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f5884d-33f7-430c-9d3e-f29ac31c4995",
   "metadata": {},
   "source": [
    "### What's next?\n",
    "\n",
    "You are now familiar with the fundamental ingredients of Ray Core, and two common options for loading and manipulating data in Ray.\n",
    "Stay tuned for **part 2** of the Intermediate tutorial, where we will use additional libraries like XGBoost and Ray Tune to walk through a real-world distributed machine learning example on Ray!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4ed789-0820-4a8c-b590-b8dc39080d20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
